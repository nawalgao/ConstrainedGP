{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal Preference Elicitation Framework\n",
    "\n",
    "Currently, this framework has been validated for only 1D (operating temp) feature./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "Load required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "sns.set_context(\"talk\", font_scale = 1.4)\n",
    "from GPFlowUnimodalPref.GPUnimodalElicit import elicit\n",
    "from GPFlowUnimodalPref.SynOccupant import datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "1. Occupant walks inside the room and is exposed to state r.\n",
    "2. Randomly change the state of the room to new state s.\n",
    "3. Ask the occupant which state they prefer. \n",
    "4. If they say state current state s, then record y as 1. If they say previous state r, then record y as 0.\n",
    "This first duel is our initial duel.\n",
    "5. Put the duel value and response in the '../data/duels/duels.csv' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the duels file\n",
    "data_file = '../GPFlowUnimodalPref/data/initial_duels/gradtrain1D.npz' # <--- you need to keep on updating this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(data_file)\n",
    "X = data['X']\n",
    "Y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter_num = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tprev = np.array(data.Tprev) # previous state (operating temp.)\n",
    "#Tcurrent = np.array(data.Tcurrent) # current state <---- elicitation framework will give you this values\n",
    "#X = np.vstack([[Tprev, Tcurrent]]).T\n",
    "#X = X.astype(float) # features need to be float\n",
    "X_prime = np.linspace(20, 30, 40)[:,None]\n",
    "#Y = np.array(data.y)[:,None] # response of the occupant <---- you need to ask occupant about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Now, we want to find the next elicited state. So, we need to use **elicit** module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_file = '../GPFlowUnimodalPref/config_files/thermal_config.json' # configuration for grid (how fine you want to be)\n",
    "trial_num = 10 # this is just to save all the plots in '../data/results/T1' if trial_num = 1 ; T2 if trial_num = 2\n",
    "model_num = 2\n",
    "mcmc = True\n",
    "reachable = True\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Aq =  elicit.IntegratedAquisition(X, Y[:,None], X_prime, config_file, model_num, mcmc, reachable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_state, next_duel, meanexp, max_exp_imp = Aq.EUI(iter_num, trial_num, savefig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 is the most important step. It outputs next state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next_state ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next duel ?\n",
    "\n",
    "One of the state is always shared between two duels. So, this is nothing but concatenation of next_state with previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_duel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max EUI ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_exp_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 (Sanity checks)\n",
    "\n",
    "Is our framework on the right track?\n",
    "\n",
    "Check -\n",
    "1. Max Expected Improvement value (is it less than the previous iteration's expected improvement? If so, GOOD!\n",
    "2. Check the Expected Improvement plots. This will be saved automatically in '../data/results/T1/exp_imp_plots/iteration_num'.\n",
    "3. Also check utility samples, how they look? Do they make sense? Is our framework going towards max? Some utility samples will also be saved in '../data/results/T1/utility_samples/iteration_num'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "\n",
    "1. Once you have verified that the framework is on the right track, change the operating temp of the room to the next_state as above. \n",
    "2. Its fine if you are not able to acheive the next state accurately, just record the measured next state value.\n",
    "2. Ask the occupant again, which state does he prefer.\n",
    "3. Add the new measured state and response to the csv  '../data/duels/duels.csv' file.\n",
    "4. Add max_exp_imp to the MEUI column.\n",
    "5. Run the notebook again with updated csv file.\n",
    "6. As you progress with the elicitation, you will notice that the ratio $(MEUI_{(i+1)} - MEUI_{(i)})/MEUI_{(i)}$ will decrease. Based on pilot study, stop the elicitation, once the ratio becomes small enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = datagen.ThermalPrefDataGen(config_file)\n",
    "Ynew = V.response_gen1D(next_duel[:,None].T)\n",
    "Ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aq.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Aq.m\n",
    "samples = Aq.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = model.get_samples_df(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xnew = np.linspace(20,27,20)[:,None]\n",
    "xx = V.normalize1D(xnew)\n",
    "meanmat = np.zeros(shape = (samples.shape[0], xx.shape[0]))\n",
    "varmat = np.zeros(shape = (samples.shape[0], xx.shape[0]))\n",
    "for i, s in sample_df.iterrows():\n",
    "    model.set_parameter_dict(s)\n",
    "    mean, v = model.predict_f(xx)\n",
    "    var = v[:,:,0]\n",
    "    meanmat[i,:] = mean[:,0]\n",
    "    varmat[i,:] = np.diag(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_utility(Xgrid, Mgrid, Vargrid):\n",
    "    \"\"\"\n",
    "    Visualize 1D utility funciton values\n",
    "    Xgrid : grid states\n",
    "    Mgrid : mean of GP at those finite grid points\n",
    "    Vargrid : variance of GP at those finite grid points\n",
    "    \"\"\"\n",
    "    Stdgrid = np.sqrt(Vargrid)\n",
    "    lower = Mgrid - 2*Stdgrid\n",
    "    upper = Mgrid + 2*Stdgrid\n",
    "    #plt.figure(figsize=(12,8))\n",
    "    #plt.plot(Xgrid[:,0], lower, 'g')\n",
    "    #plt.plot(Xgrid[:,0], upper, 'r')\n",
    "    #plt.plot(Xgrid[:,0], Mgrid, 'b')\n",
    "    \n",
    "    line, = plt.plot(Xgrid, Mgrid, lw = 2, color = 'b', label = 'utility', alpha = 0.5)\n",
    "    plt.fill_between(Xgrid[:,0], lower, upper,\n",
    "                     color = line.get_color(), alpha = 0.25)\n",
    "    plt.xlabel('Temperature degC')\n",
    "    plt.ylabel('Utility')\n",
    "    plt.title('Utility at different temp values')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini = 10\n",
    "maxi = 60\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in xrange(mini,maxi):\n",
    "    visualize_utility(xnew, meanmat[i,:], varmat[i,:])\n",
    "#plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def diff_norm_g(m, samples, Xgridnorm, Xgrid, mini, maxi):\n",
    "    \"\"\"\n",
    "    Different utilities along with the associated uncertainities\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in xrange(mini,maxi):\n",
    "        m.set_state(samples[i,:])\n",
    "        g = m.predict_g_samples(Xgridnorm, 1)\n",
    "        plt.plot(Xgrid, norm.cdf(g[0,:,:]), 'b', lw=2, alpha = 0.25)\n",
    "    a = np.linspace(19.8, 27.2, 100)\n",
    "    plt.plot(a, 0.5*np.ones(a.shape[0]), 'k')\n",
    "    plt.xlim(19.8,27.2)\n",
    "    plt.xlabel('Temperature degC')\n",
    "    plt.ylabel('Indicator')\n",
    "    plt.title('Indicator at different temp values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm_g(model, samples, xx, xnew, 0, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def diff_g(m, samples, Xgridnorm, Xgrid, mini, maxi):\n",
    "    \"\"\"\n",
    "    Different utilities along with the associated uncertainities\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in xrange(mini,maxi):\n",
    "        m.set_state(samples[i,:])\n",
    "        g = m.predict_g_samples(Xgridnorm, 1)\n",
    "        plt.plot(Xgrid, g[0,:,:], 'b', lw=2, alpha = 0.25)\n",
    "    a = np.linspace(19.8, 27.2, 100)\n",
    "    plt.plot(a, np.zeros(a.shape[0]), 'k')\n",
    "    plt.xlabel('Temperature degC')\n",
    "    plt.ylabel('Latent g')\n",
    "    plt.title('Latent g at different temp values')\n",
    "    plt.xlim(19.8,27.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_g(model, samples, xx, xnew, 0, 2600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_state(samples[2])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = model.get_samples_df(samples)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(sample_df['unimodal_model.kern_f.lengthscale'])\n",
    "plt.plot(sample_df['unimodal_model.kern_f.signal_variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(sample_df['unimodal_model.kern_f.lengthscale'],\n",
    "            sample_df['unimodal_model.kern_f.signal_variance'], 'k.', alpha = 0.15)\n",
    "plt.xlabel('signal_lengthscale')\n",
    "plt.ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aq.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.X_concat.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model.X.value\n",
    "b = model.X_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a.shape[0]/2:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([0.4, -3, 2, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[a > 0] = 1\n",
    "a[a < 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
