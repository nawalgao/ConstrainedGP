{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal Preference Elicitation Framework\n",
    "\n",
    "Currently, this framework has been validated for only 1D (operating temp) feature./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "Load required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "sns.set_context(\"talk\", font_scale = 1.4)\n",
    "from GPFlowUnimodalPref.GPUnimodalElicit import elicit\n",
    "from GPFlowUnimodalPref.SynOccupant import datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "\n",
    "1. Occupant walks inside the room and is exposed to state r.\n",
    "2. Randomly change the state of the room to new state s.\n",
    "3. Ask the occupant which state they prefer. \n",
    "4. If they say state current state s, then record y as 1. If they say previous state r, then record y as 0.\n",
    "This first duel is our initial duel.\n",
    "5. Put the duel value and response in the '../data/duels/duels.csv' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the duels file\n",
    "data_file = '../GPFlowUnimodalPref/data/initial_duels/gradtrain1D.npz' # <--- you need to keep on updating this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(data_file)\n",
    "X = data['X']\n",
    "Y = data['Y']\n",
    "Y_der = data['Y_der']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.5, 22.5],\n",
       "       [22.5, 23. ],\n",
       "       [23. , 26. ],\n",
       "       [26. , 21.5],\n",
       "       [21.5, 22.5],\n",
       "       [22.5, 24.5],\n",
       "       [24.5, 25.5],\n",
       "       [25.5, 21.5],\n",
       "       [21.5, 26.5],\n",
       "       [26.5, 22.5],\n",
       "       [22.5, 23.5],\n",
       "       [23.5, 26.5],\n",
       "       [26.5, 26.5],\n",
       "       [26.5, 26. ],\n",
       "       [26. , 25. ],\n",
       "       [25. , 21. ],\n",
       "       [21. , 25. ],\n",
       "       [25. , 22. ],\n",
       "       [22. , 24. ],\n",
       "       [24. , 22. ],\n",
       "       [22. , 21.5],\n",
       "       [21.5, 24.5],\n",
       "       [24.5, 22. ],\n",
       "       [22. , 21.5],\n",
       "       [21.5, 23.5],\n",
       "       [23.5, 22. ],\n",
       "       [22. , 21. ],\n",
       "       [21. , 21.5],\n",
       "       [21.5, 23. ],\n",
       "       [23. , 20.5],\n",
       "       [20.5, 23. ],\n",
       "       [23. , 25.5],\n",
       "       [25.5, 23.5],\n",
       "       [23.5, 26. ],\n",
       "       [26. , 23.5],\n",
       "       [23.5, 23. ],\n",
       "       [23. , 25. ],\n",
       "       [25. , 22.5],\n",
       "       [22.5, 21. ],\n",
       "       [21. , 24.5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter_num = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tprev = np.array(data.Tprev) # previous state (operating temp.)\n",
    "#Tcurrent = np.array(data.Tcurrent) # current state <---- elicitation framework will give you this values\n",
    "#X = np.vstack([[Tprev, Tcurrent]]).T\n",
    "#X = X.astype(float) # features need to be float\n",
    "X_prime = np.linspace(20, 30, 10)[:,None]\n",
    "#Y = np.array(data.y)[:,None] # response of the occupant <---- you need to ask occupant about this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Now, we want to find the next elicited state. So, we need to use **elicit** module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_file = '../GPFlowUnimodalPref/config_files/thermal_config.json' # configuration for grid (how fine you want to be)\n",
    "trial_num = 10 # this is just to save all the plots in '../data/results/T1' if trial_num = 1 ; T2 if trial_num = 2\n",
    "model_num = 3\n",
    "mcmc = True\n",
    "reachable = True\n",
    "savefig = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Model is 3\n",
      "----------------------------------------\n",
      "burn-in sampling started\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cholesky decomposition was not successful. The input might not be valid.\n\t [[Node: unimodal_model.build_likelihood_1/Cholesky = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](unimodal_model.build_likelihood_1/add)]]\n\nCaused by op u'unimodal_model.build_likelihood_1/Cholesky', defined at:\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-496a21f6ee07>\", line 1, in <module>\n    Aq =  elicit.IntegratedAquisition(X, Y, Y_der[:,None], X_prime, config_file, model_num, mcmc, reachable)\n  File \"../GPFlowUnimodalPref/GPUnimodalElicit/elicit.py\", line 46, in __init__\n    self.m, self.samples = TRAIN.mcmc(config_file)\n  File \"../GPFlowUnimodalPref/GPUnimodalPref/train.py\", line 92, in mcmc\n    self._m.optimize(maxiter= MAP_optimize_maxiter) # start near MAP\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.py\", line 250, in optimize\n    return self._optimize_np(method, tol, callback, maxiter, **kw)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.py\", line 311, in _optimize_np\n    self.compile()\n  File \"../GPFlowUnimodalPref/GPUnimodalPref/unimodal_gpmc.py\", line 68, in compile\n    optimizer = optimizer)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.py\", line 156, in compile\n    f = self.build_likelihood() + self.build_prior()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/scoping.py\", line 43, in runnable\n    return f(*args, **kwargs)\n  File \"../GPFlowUnimodalPref/GPUnimodalPref/unimodal_gpmc.py\", line 239, in build_likelihood\n    settings.numerics.jitter_level)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 704, in cholesky\n    \"Cholesky\", input=input, name=name)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n\t [[Node: unimodal_model.build_likelihood_1/Cholesky = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](unimodal_model.build_likelihood_1/add)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-496a21f6ee07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAq\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0melicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegratedAquisition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_der\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreachable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nimishawalgaonkar/Desktop/preferential_bayesian_optimization/repos/repos2018/FALL18_PREF_LEARNING/GPFlowUnimodalPref/GPUnimodalElicit/elicit.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, Y, Yder, X_prime, config_file, model_num, mcmc, reachable)\u001b[0m\n\u001b[1;32m     44\u001b[0m                       config_file, self.model_num)\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmcmc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcmc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/Desktop/preferential_bayesian_optimization/repos/repos2018/FALL18_PREF_LEARNING/GPFlowUnimodalPref/GPUnimodalPref/train.pyc\u001b[0m in \u001b[0;36mmcmc\u001b[0;34m(self, config_file)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMAP_optimize_maxiter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# start near MAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         samples = self._m.sample(num_samples, verbose= verbose,\n\u001b[0;32m---> 94\u001b[0;31m                            epsilon= epsilon, thin = thin, burn = burn, Lmax=Lmax)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.pyc\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, num_samples, Lmin, Lmax, epsilon, thin, burn, verbose, return_logprobs, RNG)\u001b[0m\n\u001b[1;32m    217\u001b[0m                               \u001b[0mLmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mburn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mburn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                               \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_free_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                               return_logprobs=return_logprobs, RNG=RNG)\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     def optimize(self, method='L-BFGS-B', tol=None, callback=None,\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/hmc.pyc\u001b[0m in \u001b[0;36msample_HMC\u001b[0;34m(f, num_samples, Lmin, Lmax, epsilon, x0, verbose, thin, burn, RNG, return_logprobs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         samples = sample_HMC(f, num_samples=burn, Lmin=Lmin, Lmax=Lmax,\n\u001b[1;32m     62\u001b[0m                              \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                              verbose=verbose, thin=1, burn=0, RNG=RNG)\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"burn-in sampling ended\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/hmc.pyc\u001b[0m in \u001b[0;36msample_HMC\u001b[0;34m(f, num_samples, Lmin, Lmax, epsilon, x0, verbose, thin, burn, RNG, return_logprobs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.pyc\u001b[0m in \u001b[0;36mobj\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_dict_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             f, g = self.session.run([self._minusF, self._minusG],\n\u001b[0;32m--> 187\u001b[0;31m                                      feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cholesky decomposition was not successful. The input might not be valid.\n\t [[Node: unimodal_model.build_likelihood_1/Cholesky = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](unimodal_model.build_likelihood_1/add)]]\n\nCaused by op u'unimodal_model.build_likelihood_1/Cholesky', defined at:\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-496a21f6ee07>\", line 1, in <module>\n    Aq =  elicit.IntegratedAquisition(X, Y, Y_der[:,None], X_prime, config_file, model_num, mcmc, reachable)\n  File \"../GPFlowUnimodalPref/GPUnimodalElicit/elicit.py\", line 46, in __init__\n    self.m, self.samples = TRAIN.mcmc(config_file)\n  File \"../GPFlowUnimodalPref/GPUnimodalPref/train.py\", line 92, in mcmc\n    self._m.optimize(maxiter= MAP_optimize_maxiter) # start near MAP\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.py\", line 250, in optimize\n    return self._optimize_np(method, tol, callback, maxiter, **kw)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.py\", line 311, in _optimize_np\n    self.compile()\n  File \"../GPFlowUnimodalPref/GPUnimodalPref/unimodal_gpmc.py\", line 68, in compile\n    optimizer = optimizer)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/model.py\", line 156, in compile\n    f = self.build_likelihood() + self.build_prior()\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/gpflow-0.4.0-py2.7.egg/gpflow/scoping.py\", line 43, in runnable\n    return f(*args, **kwargs)\n  File \"../GPFlowUnimodalPref/GPUnimodalPref/unimodal_gpmc.py\", line 239, in build_likelihood\n    settings.numerics.jitter_level)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 704, in cholesky\n    \"Cholesky\", input=input, name=name)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cholesky decomposition was not successful. The input might not be valid.\n\t [[Node: unimodal_model.build_likelihood_1/Cholesky = Cholesky[T=DT_DOUBLE, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](unimodal_model.build_likelihood_1/add)]]\n"
     ]
    }
   ],
   "source": [
    "Aq =  elicit.IntegratedAquisition(X, Y, Y_der[:,None], X_prime, config_file, model_num, mcmc, reachable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPFlowUnimodalPref.GPUnimodalPref import ker_w_der"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = ker_w_der.ExtendRBF1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmn = K.compute_Kj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[:,1][:,None]\n",
    "X1 = X[:,0][:,None]\n",
    "X11 = np.vstack([X2,X1])\n",
    "X12 = X2\n",
    "X13 = X_prime\n",
    "Xx = np.vstack([X12,X13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmn = K.compute_Kj(X11, X12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  8.82496903e-01,  2.18749112e-03, ...,\n",
       "         0.00000000e+00,  4.86978701e-01, -2.70670566e-01],\n",
       "       [ 8.82496903e-01,  1.00000000e+00,  1.11089965e-02, ...,\n",
       "         4.41248451e-01,  2.70670566e-01, -4.86978701e-01],\n",
       "       [ 2.18749112e-03,  1.11089965e-02,  1.00000000e+00, ...,\n",
       "         7.65621891e-03,  1.86332659e-05,  4.86978701e-01],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  4.41248451e-01,  7.65621891e-03, ...,\n",
       "         1.00000000e+00, -4.05815584e-01, -4.06005850e-01],\n",
       "       [ 4.86978701e-01,  2.70670566e-01,  1.86332659e-05, ...,\n",
       "        -4.05815584e-01,  1.00000000e+00, -2.46092751e-02],\n",
       "       [-2.70670566e-01, -4.86978701e-01,  4.86978701e-01, ...,\n",
       "        -4.06005850e-01, -2.46092751e-02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(kmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_state, next_duel, meanexp, max_exp_imp = Aq.EUI(iter_num, trial_num, savefig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 is the most important step. It outputs next state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next_state ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next duel ?\n",
    "\n",
    "One of the state is always shared between two duels. So, this is nothing but concatenation of next_state with previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "next_duel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max EUI ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_exp_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 (Sanity checks)\n",
    "\n",
    "Is our framework on the right track?\n",
    "\n",
    "Check -\n",
    "1. Max Expected Improvement value (is it less than the previous iteration's expected improvement? If so, GOOD!\n",
    "2. Check the Expected Improvement plots. This will be saved automatically in '../data/results/T1/exp_imp_plots/iteration_num'.\n",
    "3. Also check utility samples, how they look? Do they make sense? Is our framework going towards max? Some utility samples will also be saved in '../data/results/T1/utility_samples/iteration_num'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "\n",
    "1. Once you have verified that the framework is on the right track, change the operating temp of the room to the next_state as above. \n",
    "2. Its fine if you are not able to acheive the next state accurately, just record the measured next state value.\n",
    "2. Ask the occupant again, which state does he prefer.\n",
    "3. Add the new measured state and response to the csv  '../data/duels/duels.csv' file.\n",
    "4. Add max_exp_imp to the MEUI column.\n",
    "5. Run the notebook again with updated csv file.\n",
    "6. As you progress with the elicitation, you will notice that the ratio $(MEUI_{(i+1)} - MEUI_{(i)})/MEUI_{(i)}$ will decrease. Based on pilot study, stop the elicitation, once the ratio becomes small enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = datagen.ThermalPrefDataGen(config_file)\n",
    "Ynew = V.response_gen1D(next_duel[:,None].T)\n",
    "Ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Aq.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Aq.m\n",
    "samples = Aq.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = model.get_samples_df(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xnew = np.linspace(20,27,20)[:,None]\n",
    "xx = V.normalize1D(xnew)\n",
    "meanmat = np.zeros(shape = (samples.shape[0], xx.shape[0]))\n",
    "varmat = np.zeros(shape = (samples.shape[0], xx.shape[0]))\n",
    "for i, s in sample_df.iterrows():\n",
    "    model.set_parameter_dict(s)\n",
    "    mean, v = model.predict_f(xx)\n",
    "    var = v[:,:,0]\n",
    "    meanmat[i,:] = mean[:,0]\n",
    "    varmat[i,:] = np.diag(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_utility(Xgrid, Mgrid, Vargrid):\n",
    "    \"\"\"\n",
    "    Visualize 1D utility funciton values\n",
    "    Xgrid : grid states\n",
    "    Mgrid : mean of GP at those finite grid points\n",
    "    Vargrid : variance of GP at those finite grid points\n",
    "    \"\"\"\n",
    "    Stdgrid = np.sqrt(Vargrid)\n",
    "    lower = Mgrid - 2*Stdgrid\n",
    "    upper = Mgrid + 2*Stdgrid\n",
    "    #plt.figure(figsize=(12,8))\n",
    "    #plt.plot(Xgrid[:,0], lower, 'g')\n",
    "    #plt.plot(Xgrid[:,0], upper, 'r')\n",
    "    #plt.plot(Xgrid[:,0], Mgrid, 'b')\n",
    "    \n",
    "    line, = plt.plot(Xgrid, Mgrid, lw = 2, color = 'b', label = 'utility', alpha = 0.5)\n",
    "    plt.fill_between(Xgrid[:,0], lower, upper,\n",
    "                     color = line.get_color(), alpha = 0.25)\n",
    "    plt.xlabel('Temperature degC')\n",
    "    plt.ylabel('Utility')\n",
    "    plt.title('Utility at different temp values')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mini = 10\n",
    "maxi = 60\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in xrange(mini,maxi):\n",
    "    visualize_utility(xnew, meanmat[i,:], varmat[i,:])\n",
    "#plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def diff_norm_g(m, samples, Xgridnorm, Xgrid, mini, maxi):\n",
    "    \"\"\"\n",
    "    Different utilities along with the associated uncertainities\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in xrange(mini,maxi):\n",
    "        m.set_state(samples[i,:])\n",
    "        g = m.predict_g_samples(Xgridnorm, 1)\n",
    "        plt.plot(Xgrid, norm.cdf(g[0,:,:]), 'b', lw=2, alpha = 0.25)\n",
    "    a = np.linspace(19.8, 27.2, 100)\n",
    "    plt.plot(a, 0.5*np.ones(a.shape[0]), 'k')\n",
    "    plt.xlim(19.8,27.2)\n",
    "    plt.xlabel('Temperature degC')\n",
    "    plt.ylabel('Indicator')\n",
    "    plt.title('Indicator at different temp values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_norm_g(model, samples, xx, xnew, 0, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def diff_g(m, samples, Xgridnorm, Xgrid, mini, maxi):\n",
    "    \"\"\"\n",
    "    Different utilities along with the associated uncertainities\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in xrange(mini,maxi):\n",
    "        m.set_state(samples[i,:])\n",
    "        g = m.predict_g_samples(Xgridnorm, 1)\n",
    "        plt.plot(Xgrid, g[0,:,:], 'b', lw=2, alpha = 0.25)\n",
    "    a = np.linspace(19.8, 27.2, 100)\n",
    "    plt.plot(a, np.zeros(a.shape[0]), 'k')\n",
    "    plt.xlabel('Temperature degC')\n",
    "    plt.ylabel('Latent g')\n",
    "    plt.title('Latent g at different temp values')\n",
    "    plt.xlim(19.8,27.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_g(model, samples, xx, xnew, 0, 2600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.set_state(samples[2])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df = model.get_samples_df(samples)\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(sample_df['unimodal_model.kern_f.lengthscale'])\n",
    "plt.plot(sample_df['unimodal_model.kern_f.signal_variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(sample_df['unimodal_model.kern_f.lengthscale'],\n",
    "            sample_df['unimodal_model.kern_f.signal_variance'], 'k.', alpha = 0.15)\n",
    "plt.xlabel('signal_lengthscale')\n",
    "plt.ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Aq.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.X_concat.value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model.X.value\n",
    "b = model.X_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[a.shape[0]/2:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([0.4, -3, 2, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a[a > 0] = 1\n",
    "a[a < 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aq.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aq.X_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
