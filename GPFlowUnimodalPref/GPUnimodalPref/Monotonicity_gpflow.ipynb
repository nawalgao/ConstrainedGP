{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "from gpflow.param import Param, Parameterized, AutoFlow\n",
    "from gpflow._settings import settings\n",
    "import tensorflow as tf\n",
    "float_type = settings.dtypes.float_type\n",
    "int_type = settings.dtypes.int_type\n",
    "np_float_type = np.float32 if float_type is tf.float32 else np.float64\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\", font_scale= 1.4)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendRBF1D(gpflow.kernels.Kern):\n",
    "    \"\"\"\n",
    "    Kernel for monotonicity models\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        gpflow.kernels.Kern.__init__(self, input_dim = 1, active_dims= [0])\n",
    "        self.lengthscale = gpflow.param.Param(1.0, transform=gpflow.transforms.positive)\n",
    "        self.signal_variance = gpflow.param.Param(1.0, transform=gpflow.transforms.positive)\n",
    "    \n",
    "    def Kn(self, X1, X2):\n",
    "        cov = self.signal_variance * tf.exp(-1./(2 * tf.square(self.lengthscale)) * tf.square(X1 - tf.transpose(X2)))\n",
    "        return cov\n",
    "    \n",
    "    def Kd(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Covariance between gaussian process at X2 and its derivative at X1\n",
    "        \"\"\"\n",
    "        cov = (self.signal_variance * \n",
    "               tf.exp(-1./(2 * tf.square(self.lengthscale)) * tf.square(X1 - tf.transpose(X2))) *\n",
    "              (-1./tf.square(self.lengthscale) * (X1 - tf.transpose(X2))))\n",
    "        return cov\n",
    "    \n",
    "    def Kdd(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Covariance between derivatives of gaussian process at X1 and X2\n",
    "        \"\"\"\n",
    "        cov = (self.signal_variance * \n",
    "               tf.exp(-1./(2 * tf.square(self.lengthscale)) * tf.square(X1 - tf.transpose(X2)))* \n",
    "               1./tf.square(self.lengthscale) *\n",
    "              (1. - 1./tf.square(self.lengthscale) * tf.square(X1 - tf.transpose(X2))))\n",
    "        return cov\n",
    "    \n",
    "    def K(self, X, X_prime):\n",
    "        \"\"\"\n",
    "        Covariance matrix for joint Normal distribution over GP and its derivative\n",
    "        \"\"\"\n",
    "        K_f_f = self.Kn(X, X)\n",
    "        K_f_fprime = self.Kd(X, X_prime)\n",
    "        K_fprime_f = tf.transpose(K_f_fprime)\n",
    "        K_fprime_fprime = self.Kdd(X_prime, X_prime)\n",
    "        Knew1 = tf.concat([K_f_f, K_f_fprime], 1)\n",
    "        Knew2 = tf.concat([K_fprime_f, K_fprime_fprime], 1)\n",
    "        K_joint = tf.concat([Knew1, Knew2], 0)\n",
    "        return K_joint \n",
    "        \n",
    "    @AutoFlow((float_type, [None, None]), (float_type, [None, None]))\n",
    "    def compute_Kn(self, X, Z):\n",
    "        return self.Kn(X, Z)\n",
    "    \n",
    "    @AutoFlow((float_type, [None, None]), (float_type, [None, None]))\n",
    "    def compute_Kd(self, X, Z):\n",
    "        return self.Kd(X, Z)\n",
    "    \n",
    "    @AutoFlow((float_type, [None, None]), (float_type, [None, None]))\n",
    "    def compute_Kdd(self, X, Z):\n",
    "        return self.Kdd(X, Z)\n",
    "    \n",
    "    @AutoFlow((float_type, [None, None]), (float_type, [None, None]))\n",
    "    def compute_K(self, X, X_prime):\n",
    "        return self.K(X, X_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,2,3])[:,None]\n",
    "X_prime = np.array([4,5])[:,None]\n",
    "K = ExtendRBF1D()\n",
    "aa = K.compute_K(X, X_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gpflow.likelihoods import Likelihood\n",
    "from gpflow.likelihoods import probit\n",
    "from gpflow import densities\n",
    "\n",
    "class MonotoneLikelihood(Likelihood):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Likelihood for Gaussian Process with monotonicity constraints\n",
    "        \"\"\"\n",
    "        Likelihood.__init__(self)\n",
    "        self.nu = 1e-6\n",
    "        self.signal_variance = Param(1.0, transforms.positive)\n",
    "    \n",
    "    def logp_ygf(self, F, Y):\n",
    "        return tf.reduce_sum(densities.gaussian(F, Y, self.signal_variance))\n",
    "    \n",
    "    def logp_m(self, F_prime, invlink = probit):\n",
    "        Y = tf.ones(tf.shape(F_prime).shape.as_list(), tf.int32) \n",
    "        return tf.reduce_sum(densities.bernoulli(self.invlink(1./self.nu*F_prime), Y))\n",
    "    \n",
    "    def logp(F, Y, F_prime):\n",
    "        log_like_ygp = self.logp_ygf(F, Y)\n",
    "        log_like_m = self.logpm(F_prime, invlink = probit)\n",
    "        log_like = log_like_ygp + log_like_m\n",
    "        return log_like    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.mean_functions import Zero\n",
    "from gpflow.param import Parameterized, AutoFlow, DataHolder\n",
    "\n",
    "class MonotoneGP(gpflow.model.Model):\n",
    "    def __init__(self, X_concat, Y, name = 'monotonic_model'):\n",
    "        \"\"\"\n",
    "        X_concat is a data vector, size (N + M) x 1\n",
    "        X_concat = (X, X_der_loc)\n",
    "        Y is a data matrix, size N x 1 \n",
    "    \n",
    "        This is a vanilla implementation of a GP with monotonicity contraints.\n",
    "        \n",
    "        Refer:\n",
    "        https://bayesopt.github.io/papers/2017/9.pdf\n",
    "        \n",
    "        \"\"\"\n",
    "        if not X_concat.shape[1] == 1:\n",
    "            raise ValueError('Currently, GP with monotonicity is only supported for 1D')\n",
    "        \n",
    "        # Initialize the model\n",
    "        gpflow.Model.__init__(self, name)\n",
    "        # Zero mean function for now\n",
    "        self.mean_function = Zero()\n",
    "        \n",
    "        # Initialize data\n",
    "        if isinstance(X_concat, np.ndarray):\n",
    "            #: X is a data matrix; each row represents one instance\n",
    "            X_concat = DataHolder(X_concat)\n",
    "        if isinstance(Y, np.ndarray):\n",
    "            #: Y is a data matrix, rows correspond to the rows in X, columns are treated independently\n",
    "            Y = DataHolder(Y)\n",
    "        \n",
    "        # Define kernel\n",
    "        self.kern = ExtendRBF1D()\n",
    "        \n",
    "        # Define likelihood \n",
    "        self.likelihood = MonotoneLikelihood()\n",
    "        self.likelihood._check_targets(Y.value)\n",
    "        \n",
    "        # Initialize\n",
    "        self.Y = Y\n",
    "        self.X_concat = X_concat\n",
    "        \n",
    "        self._session = None\n",
    "    \n",
    "    def build_predict(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @AutoFlow((float_type, [None, None]))\n",
    "    def predict_f(self, Xnew):\n",
    "        \"\"\"\n",
    "        Compute the mean and variance of the latent function(s)\n",
    "        at the points `Xnew`.\n",
    "        \"\"\"\n",
    "        return self.build_predict(Xnew)\n",
    "\n",
    "    @AutoFlow((float_type, [None, None]))\n",
    "    def predict_f_full_cov(self, Xnew):\n",
    "        \"\"\"\n",
    "        Compute the mean and covariance matrix of the latent function(s) at the\n",
    "        points Xnew.\n",
    "        \"\"\"\n",
    "        return self.build_predict(Xnew, full_cov=True)\n",
    "\n",
    "    @AutoFlow((float_type, [None, None]), (tf.int32, []))\n",
    "    def predict_f_samples(self, Xnew, num_samples):\n",
    "        \"\"\"\n",
    "        Produce samples from the posterior latent function(s) at the points\n",
    "        Xnew.\n",
    "        \"\"\"\n",
    "        mu, var = self.build_predict(Xnew, full_cov=True)\n",
    "        jitter = tf.eye(tf.shape(mu)[0], dtype=float_type) * settings.numerics.jitter_level\n",
    "        samples = []\n",
    "        for i in range(self.num_latent):\n",
    "            L = tf.cholesky(var[:, :, i] + jitter)\n",
    "            shape = tf.stack([tf.shape(L)[0], num_samples])\n",
    "            V = tf.random_normal(shape, dtype=settings.dtypes.float_type)\n",
    "            samples.append(mu[:, i:i + 1] + tf.matmul(L, V))\n",
    "        return tf.transpose(tf.stack(samples))\n",
    "\n",
    "    @AutoFlow((float_type, [None, None]))\n",
    "    def predict_y(self, Xnew):\n",
    "        \"\"\"\n",
    "        Compute the mean and variance of held-out data at the points Xnew\n",
    "        \"\"\"\n",
    "        pred_f_mean, pred_f_var = self.build_predict(Xnew)\n",
    "        return self.likelihood.predict_mean_and_var(pred_f_mean, pred_f_var)\n",
    "\n",
    "    @AutoFlow((float_type, [None, None]), (float_type, [None, None]))\n",
    "    def predict_density(self, Xnew, Ynew):\n",
    "        \"\"\"\n",
    "        Compute the (log) density of the data Ynew at the points Xnew\n",
    "\n",
    "        Note that this computes the log density of the data individually,\n",
    "        ignoring correlations between them. The result is a matrix the same\n",
    "        shape as Ynew containing the log densities.\n",
    "        \"\"\"\n",
    "        pred_f_mean, pred_f_var = self.build_predict(Xnew)\n",
    "        return self.likelihood.predict_density(pred_f_mean, pred_f_var, Ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gpflow.priors import Gaussian\n",
    "class MonotoneGPMC(MonotoneGP):\n",
    "    def __init__(self, X, Y, X_prime, num_latent = None):\n",
    "        \"\"\"\n",
    "        X is a data vector, size N x 1\n",
    "        X_prime is a vector, size M x 1\n",
    "        Y is a data matrix, size N x 1 \n",
    "    \n",
    "        This is a vanilla implementation of a GP with monotonicity contraints and HMC sampling\n",
    "        Refer:\n",
    "        https://bayesopt.github.io/papers/2017/9.pdf\n",
    "        \"\"\"\n",
    "        X_concat = np.vstack([X, X_prime])\n",
    "        X_concat = DataHolder(X_concat, on_shape_change='recompile')\n",
    "        Y = DataHolder(Y, on_shape_change='recompile')\n",
    "        MonotoneGP.__init__(self, X_concat, Y)\n",
    "        self.num_data = X_concat.shape[0]\n",
    "        self.num_x_points = X.shape[0]\n",
    "        self.num_der_points = X_prime.shape[0]\n",
    "        self.num_latent = num_latent or Y.shape[1]\n",
    "        self.V = Param(np.zeros((self.num_data, self.num_latent)))\n",
    "        self.V.prior = Gaussian(0., 1.)\n",
    "    def compile(self, session = None, graph = None, optimizer = None):\n",
    "        \"\"\"\n",
    "        Before calling the standard compile function, check to see if the size\n",
    "        of the data has changed and add parameters appropriately.\n",
    "\n",
    "        This is necessary because the shape of the parameters depends on the\n",
    "        shape of the data.\n",
    "        \"\"\"\n",
    "        if not self.num_data == self.X_concat.shape[0]:\n",
    "            self.num_data = self.X_concat.shape[0]\n",
    "            self.V = Param(np.zeros((self.num_data, self.num_latent)))\n",
    "            self.V.prior = Gaussian(0., 1.)\n",
    "        \n",
    "        return super(MonotoneGPMC, self).compile(session = session,\n",
    "                                                 graph = graph,\n",
    "                                                 optimizer = optimizer)\n",
    "    \n",
    "    def build_likelihood(self):\n",
    "        K = self.kern.K(self.X)\n",
    "        L = tf.cholesky(K + tf.eye(tf.shape(self.X)[0], dtype=float_type)*settings.numerics.jitter_level)\n",
    "        F_concat = tf.matmul(L, self.V) + self.mean_function(self.X)\n",
    "        F, F_prime = tf.split(F_concat, [self.num_x_points, self.num_der_points])\n",
    "        log_like = self.likelihood.logp(F, self.Y, F_prime)\n",
    "        return log_like\n",
    "    \n",
    "    def build_predict(self, Xnew, full_cov=False):\n",
    "        \"\"\"\n",
    "        Xnew is a data matrix, point at which we want to predict\n",
    "\n",
    "        This method computes\n",
    "\n",
    "            p(F* | (F=LV) )\n",
    "\n",
    "        where F* are points on the GP at Xnew, F=LV are points on the GP at X.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        raise ValueError(\"Under construction\")\n",
    "        \n",
    "        mu, var = conditional(Xnew, self.X, self.kern, self.V,\n",
    "                              full_cov=full_cov,\n",
    "                              q_sqrt=None, whiten=True)\n",
    "        return mu + self.mean_function(Xnew), var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 10)\n",
    "X_der = np.linspace(0,1, 50)\n",
    "Y = 5 * X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a23834f90>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEJCAYAAACe4zzCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ff981d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, Y, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@NameScoped(\"conditional\")\n",
    "def conditional(Xnew, X, kern, f, full_cov=False, q_sqrt=None, whiten=False):\n",
    "    \"\"\"\n",
    "    Given F_concat, representing the GP at the points X,\n",
    "    produce the mean and (co-)variance of the GP at the points Xnew.\n",
    "\n",
    "    Additionally, there may be Gaussian uncertainty about F as represented by\n",
    "    q_sqrt. In this case `f` represents the mean of the distribution and\n",
    "    q_sqrt the square-root of the covariance.\n",
    "\n",
    "    Additionally, the GP may have been centered (whitened) so that\n",
    "        p(v) = N( 0, I)\n",
    "        f = L v\n",
    "    thus\n",
    "        p(f) = N(0, LL^T) = N(0, K).\n",
    "    In this case 'f' represents the values taken by v.\n",
    "\n",
    "    The method can either return the diagonals of the covariance matrix for\n",
    "    each output of the full covariance matrix (full_cov).\n",
    "\n",
    "    We assume K independent GPs, represented by the columns of f (and the\n",
    "    last dimension of q_sqrt).\n",
    "\n",
    "     - Xnew is a data matrix, size N x D\n",
    "     - X are data points, size M x D\n",
    "     - kern is a GPflow kernel\n",
    "     - f is a data matrix, M x K, representing the function values at X, for K functions.\n",
    "     - q_sqrt (optional) is a matrix of standard-deviations or Cholesky\n",
    "       matrices, size M x K or M x M x K\n",
    "     - whiten (optional) is a boolean: whether to whiten the representation\n",
    "       as described above.\n",
    "\n",
    "    These functions are now considered deprecated, subsumed into this one:\n",
    "        gp_predict\n",
    "        gaussian_gp_predict\n",
    "        gp_predict_whitened\n",
    "        gaussian_gp_predict_whitened\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # compute kernel stuff\n",
    "    num_data = tf.shape(X)[0]  # M\n",
    "    num_func = tf.shape(f)[1]  # K\n",
    "    Kmn = kern.K(X, Xnew)\n",
    "    Kmm = kern.K(X) + tf.eye(num_data, dtype=float_type) * settings.numerics.jitter_level\n",
    "    Lm = tf.cholesky(Kmm)\n",
    "\n",
    "    # Compute the projection matrix A\n",
    "    A = tf.matrix_triangular_solve(Lm, Kmn, lower=True)\n",
    "\n",
    "    # compute the covariance due to the conditioning\n",
    "    if full_cov:\n",
    "        fvar = kern.K(Xnew) - tf.matmul(A, A, transpose_a=True)\n",
    "        shape = tf.stack([num_func, 1, 1])\n",
    "    else:\n",
    "        fvar = kern.Kdiag(Xnew) - tf.reduce_sum(tf.square(A), 0)\n",
    "        shape = tf.stack([num_func, 1])\n",
    "    fvar = tf.tile(tf.expand_dims(fvar, 0), shape)  # K x N x N or K x N\n",
    "\n",
    "    # another backsubstitution in the unwhitened case\n",
    "    if not whiten:\n",
    "        A = tf.matrix_triangular_solve(tf.transpose(Lm), A, lower=False)\n",
    "\n",
    "    # construct the conditional mean\n",
    "    fmean = tf.matmul(A, f, transpose_a=True)\n",
    "\n",
    "    if q_sqrt is not None:\n",
    "        if q_sqrt.get_shape().ndims == 2:\n",
    "            LTA = A * tf.expand_dims(tf.transpose(q_sqrt), 2)  # K x M x N\n",
    "        elif q_sqrt.get_shape().ndims == 3:\n",
    "            L = tf.matrix_band_part(tf.transpose(q_sqrt, (2, 0, 1)), -1, 0)  # K x M x M\n",
    "            A_tiled = tf.tile(tf.expand_dims(A, 0), tf.stack([num_func, 1, 1]))\n",
    "            LTA = tf.matmul(L, A_tiled, transpose_a=True)  # K x M x N\n",
    "        else:  # pragma: no cover\n",
    "            raise ValueError(\"Bad dimension for q_sqrt: %s\" %\n",
    "                             str(q_sqrt.get_shape().ndims))\n",
    "        if full_cov:\n",
    "            fvar = fvar + tf.matmul(LTA, LTA, transpose_a=True)  # K x N x N\n",
    "        else:\n",
    "            fvar = fvar + tf.reduce_sum(tf.square(LTA), 1)  # K x N\n",
    "    fvar = tf.transpose(fvar)  # N x K or N x N x K\n",
    "\n",
    "    return fmean, fvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
    "a = tf.shape(t)  # [2, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TensorShape.as_list of TensorShape([Dimension(3)])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.eye(2)\n",
    "c = np.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = DataHolder(a)\n",
    "d = DataHolder(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gpflow.param.DataHolder at 0x1a232b21d0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensors in list passed to 'values' of 'ConcatV2' Op have types [<NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>] that don't all match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-8f37b17f6274>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1179\u001b[0m               tensor_shape.scalar())\n\u001b[1;32m   1180\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 949\u001b[0;31m         \"ConcatV2\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m    950\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nimishawalgaonkar/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    481\u001b[0m                                 (prefix, dtype.name))\n\u001b[1;32m    482\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s that don't all match.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m               \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s that are invalid.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensors in list passed to 'values' of 'ConcatV2' Op have types [<NOT CONVERTIBLE TO TENSOR>, <NOT CONVERTIBLE TO TENSOR>] that don't all match."
     ]
    }
   ],
   "source": [
    "r = tf.concat(values = [g, f], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pos_def(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
